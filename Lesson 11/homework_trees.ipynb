{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3897748-cea1-4214-94e0-fb1e2c4971de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa774a7-d540-426a-ae0d-eb5509dd90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Один узел дерева решений.\n",
    "\n",
    "    Attributes:\n",
    "        feature (int | None): Индекс признака, по которому происходит разбиение.\n",
    "        threshold (float | None): Пороговое значение для разбиения.\n",
    "        left (Node | None): Левый потомок.\n",
    "        right (Node | None): Правый потомок.\n",
    "        value (float | int | None): Значение предсказания в листе.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf(self):\n",
    "        \"\"\"Проверяет, является ли узел листом.\n",
    "\n",
    "        Returns:\n",
    "            bool: True, если это лист (у узла есть value).\n",
    "        \"\"\"\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b208e04c-a71e-40c5-ae08-f35f3f50abed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisiontTree:\n",
    "    \"\"\"Простое дерево решений (CART) для классификации и регрессии.\n",
    "\n",
    "    Поддерживает две задачи:\n",
    "        - Классификация (criterion = 'gini')\n",
    "        - Регрессия (criterion = 'mse')\n",
    "\n",
    "    Args:\n",
    "        task (str): Тип задачи — 'classification' или 'regression'.\n",
    "        max_depth (int): Максимальная глубина дерева.\n",
    "        min_samples_split (int): Минимальное количество примеров для разбиения.\n",
    "    \"\"\"\n",
    "    def __init__(self, task=\"classification\", max_depth=3, min_samples_split=2):\n",
    "        self.task = task\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Строит дерево решений.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Матрица признаков (n_samples, n_features).\n",
    "            y (np.ndarray): Вектор ответов (n_samples,).\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Делает предсказания для новых объектов.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Матрица признаков (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Вектор предсказаний (n_samples,).\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        return np.array([self._predict_one(x, self.root) for x in X])\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        \"\"\"Рекурсивно строит дерево решений.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Матрица признаков текущего узла.\n",
    "            y (np.ndarray): Ответы текущего узла.\n",
    "            depth (int): Текущая глубина дерева.\n",
    "\n",
    "        Returns:\n",
    "            Node: Корень поддерева (ветвь или лист).\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if depth >= self.max_depth or n_samples < self.min_samples_split:\n",
    "            return self._create_leaf(y)\n",
    "\n",
    "        best_features, best_threshold, nest_score = None, None, float(\"inf\")\n",
    "        best_left, best_right = None, None\n",
    "\n",
    "        for features in range(n_features):\n",
    "            values = np.unique(X[:, feature])\n",
    "            for threshold in values:\n",
    "                left_mask = X[:, feature] <= threshold\n",
    "                right_mask = X[:, feature] > threshold\n",
    "                if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n",
    "                    continue\n",
    "\n",
    "                if self.task == \"classification\":\n",
    "                    score = self._gini(y[left_mask], y[right_mask])\n",
    "                else:\n",
    "                    score = self._mse(y[left_mask], y[right_mask])\n",
    "\n",
    "                if score < best_score:\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_score = score\n",
    "                    best_left = left_mask\n",
    "                    best_right = right_mask\n",
    "\n",
    "        if best_feature is None:\n",
    "            return self._create_leaf(y)\n",
    "\n",
    "        left_branch = self._build_tree(X[best_left], y[best_left], depth + 1)\n",
    "        right_branch = self._build_tree(X[best_right], y[best_right], depth + 1)\n",
    "\n",
    "        return Node(feature=best_feature, threshold=best_threshold, left=left_branch, right=right_branch)\n",
    "\n",
    "    def _create_leaf(self, y):\n",
    "        \"\"\"Создаёт листовой узел (с предсказанием).\n",
    "\n",
    "        Args:\n",
    "            y (np.ndarray): Целевые значения в листе.\n",
    "\n",
    "        Returns:\n",
    "            Node: Узел-лист с заполненным value.\n",
    "        \"\"\"\n",
    "        if self.task == \"classification\":\n",
    "            values, counts = np.unique(y, return_counts=True)\n",
    "            most_common = values[np.argmax(counts)]\n",
    "            return Node(value=int(most_common))\n",
    "        else:\n",
    "            return Node(value=float(np.mean(y)))\n",
    "\n",
    "    def _predict_one(self, x, node):\n",
    "        \"\"\"Спускает один объект по дереву до листа.\n",
    "\n",
    "        Args:\n",
    "            x (np.ndarray): Один объект (вектор признаков).\n",
    "            node (Node): Текущий узел.\n",
    "\n",
    "        Returns:\n",
    "            float | int: Предсказание (число или класс).\n",
    "        \"\"\"\n",
    "        if node.is_leaf():\n",
    "            return node.value\n",
    "            \n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._predict_one(x, node.left)\n",
    "        else:\n",
    "            return self._predict_one(x, node.right)\n",
    "\n",
    "    def _gini(self, left_y, right_y):\n",
    "        \"\"\"Вычисляет impurity (грязность) для классификации.\n",
    "\n",
    "        Args:\n",
    "            left_y (np.ndarray): Ответы левого подмножества.\n",
    "            right_y (np.ndarray): Ответы правого подмножества.\n",
    "\n",
    "        Returns:\n",
    "            float: Средняя \"грязность\" двух частей.\n",
    "        \"\"\"\n",
    "        def gini_part(y):\n",
    "            if len(y) == 0:\n",
    "                return 0\n",
    "            _, counts = np.unique(y, return_counts=True)\n",
    "            p = counts / len(y)\n",
    "            return 1 - np.sum(p ** 2)\n",
    "        n = len(left_y) + len(right_y)\n",
    "        return (len(left_y)/n) * gini_part(left_y) + (len(right_y)/n) * gini_part(right_y)\n",
    "\n",
    "    def _mse(self, left_y, right_y):\n",
    "        \"\"\"Вычисляет impurity (грязность) для регрессии (через MSE).\n",
    "\n",
    "        Args:\n",
    "            left_y (np.ndarray): Ответы левого подмножества.\n",
    "            right_y (np.ndarray): Ответы правого подмножества.\n",
    "\n",
    "        Returns:\n",
    "            float: Средняя квадратичная ошибка.\n",
    "        \"\"\"\n",
    "        def mse_part(y):\n",
    "            if len(y) == 0:\n",
    "                return 0\n",
    "            return np.mean((y - np.mean(y)) ** 2)\n",
    "        n = len(left_y) + len(right_y)\n",
    "        return (len(left_y)/n) * mse_part(left_y) + (len(right_y)/n) * mse_part(right_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54bf1b78-893e-452a-b4bb-4509e8762438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \"\"\"Простой Random Forest поверх DecisionTree (классификация/регрессия).\n",
    "\n",
    "    Работает по принципу бэггинга:\n",
    "    - Каждый базовый обучаемый алгоритм — это MyDecisionTree.\n",
    "    - Для каждого дерева берём бутстрэп-выборку объектов (строки).\n",
    "    - (Опционально) Для каждого дерева берём случайное подмножество признаков (столбцы).\n",
    "\n",
    "    Args:\n",
    "        task (str): 'classification' или 'regression'.\n",
    "        n_estimators (int): Количество деревьев в лесе.\n",
    "        max_depth (int): Максимальная глубина каждого дерева.\n",
    "        min_samples_split (int): Минимум объектов для разбиения узла в дереве.\n",
    "        bootstrap (bool): Использовать ли бутстрэп (выбор с возвращением).\n",
    "        max_features_per_tree (str | int | None): Сколько признаков брать на дерево.\n",
    "            - None: взять все признаки.\n",
    "            - 'sqrt': взять round(sqrt(n_features)).\n",
    "            - int: взять ровно указанное число признаков.\n",
    "        random_state (int | None): Фиксирует случайность для воспроизводимости.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 task=\"classification\",\n",
    "                 n_estimators=50,\n",
    "                 max_depth=3,\n",
    "                 min_samples_split=2,\n",
    "                 bootstrap=True,\n",
    "                 max_features_per_tree=None,\n",
    "                 random_state=None):\n",
    "        self.task = task\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.bootstrap = bootstrap\n",
    "        self.max_features_per_tree = max_features_per_tree\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.trees_ = []\n",
    "        self.features_idx_ = []\n",
    "        self.rs_ = np.random.RandomState(random_state)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучает лес.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Матрица признаков формы (n_samples, n_features).\n",
    "            y (np.ndarray): Вектор ответов формы (n_samples,).\n",
    "\n",
    "        Returns:\n",
    "            SimpleRandomForest: self.\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        self.trees_ = []\n",
    "        self.features_idx_ = []\n",
    "\n",
    "        for m in range(self.n_estimators):\n",
    "            feat_idx = self._choose_features(n_features)\n",
    "            self.features_idx_.append(feat_idx)\n",
    "\n",
    "            if self.bootstrap:\n",
    "                rows = self.rs_.randint(0, n_samples, size=n_samples)  # с возвращением\n",
    "            else:\n",
    "                rows = np.arange(n_samples)\n",
    "\n",
    "            X_sub = X[rows][:, feat_idx]\n",
    "            y_sub = y[rows]\n",
    "\n",
    "            tree = DecisionTree(task=self.task,\n",
    "                                max_depth=self.max_depth,\n",
    "                                min_samples_split=self.min_samples_split)\n",
    "            tree.fit(X_sub, y_sub)\n",
    "            self.trees_.append(tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Делает предсказания ансамбля.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Матрица признаков формы (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Предсказания формы (n_samples,).\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        all_preds = []\n",
    "        for tree, feat_idx in zip(self.trees_, self.features_idx_):\n",
    "            preds = tree.predict(X[:, feat_idx])\n",
    "            all_preds.append(preds)\n",
    "        all_preds = np.vstack(all_preds)  # shape: (n_estimators, n_samples)\n",
    "\n",
    "        if self.task == \"classification\":\n",
    "            n_samples = X.shape[0]\n",
    "            final = np.zeros(n_samples, dtype=int)\n",
    "            for i in range(n_samples):\n",
    "                votes = all_preds[:, i].astype(int)\n",
    "                final[i] = np.bincount(votes).argmax()\n",
    "            return final\n",
    "        else:\n",
    "            return np.mean(all_preds, axis=0)\n",
    "\n",
    "    def _choose_features(self, n_features):\n",
    "        \"\"\"Выбирает индексы признаков для конкретного дерева.\n",
    "\n",
    "        Args:\n",
    "            n_features (int): Общее число признаков.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Отсортированный массив индексов выбранных признаков.\n",
    "        \"\"\"\n",
    "        if self.max_features_per_tree is None:\n",
    "            return np.arange(n_features)\n",
    "\n",
    "        if isinstance(self.max_features_per_tree, str):\n",
    "            if self.max_features_per_tree == \"sqrt\":\n",
    "                k = max(1, int(round(np.sqrt(n_features))))\n",
    "            else:\n",
    "                k = n_features\n",
    "        elif isinstance(self.max_features_per_tree, int):\n",
    "            k = max(1, min(self.max_features_per_tree, n_features))\n",
    "        else:\n",
    "            k = n_features\n",
    "\n",
    "        return np.sort(self.rs_.choice(n_features, size=k, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a23c1577-be32-441d-aaef-2312e585dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(z):\n",
    "    \"\"\"Сигмоида.\"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def _logit(p):\n",
    "    \"\"\"Обратная к сигмоиде (logit). Защищаемся от 0 и 1.\"\"\"\n",
    "    p = np.clip(p, 1e-6, 1 - 1e-6)\n",
    "    return np.log(p / (1 - p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e53589a7-ea43-407e-8594-7174e647683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    \"\"\"Простой Gradient Boosting поверх MyDecisionTree.\n",
    "\n",
    "    Реализует две задачи:\n",
    "        - 'regression': градиентный бустинг по MSE (обучаем деревья на остатках y - F).\n",
    "        - 'binary': логистический бустинг (log-loss). Держим логиты F, считаем p=sigmoid(F).\n",
    "                    Псевдо-остатки r = y - p, обучаем регрессионное дерево на r.\n",
    "\n",
    "    Базовый алгоритм (weak learner): MyDecisionTree с task='regression'.\n",
    "\n",
    "    Args:\n",
    "        task (str): 'regression' или 'binary'.\n",
    "        n_estimators (int): Количество слабых деревьев.\n",
    "        learning_rate (float): Шаг обучения (умножается на предсказание дерева).\n",
    "        max_depth (int): Максимальная глубина каждого базового дерева.\n",
    "        min_samples_split (int): Минимум объектов для разбиения узла в дереве.\n",
    "        subsample (float): Доля объектов для стохастического бустинга (0 < subsample <= 1.0).\n",
    "        random_state (int | None): Фиксирует случайность для воспроизводимости.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 task=\"regression\",\n",
    "                 n_estimators=100,\n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=3,\n",
    "                 min_samples_split=2,\n",
    "                 subsample=1.0,\n",
    "                 random_state=None):\n",
    "        self.task = task\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.subsample = subsample\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.init_ = 0.0\n",
    "        self.trees_ = []\n",
    "        self.rs_ = np.random.RandomState(random_state)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучает бустинг.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Матрица признаков формы (n_samples, n_features).\n",
    "            y (np.ndarray): Вектор целевой переменной формы (n_samples,).\n",
    "                - Для task='regression' — любые вещественные значения.\n",
    "                - Для task='binary' — метки 0/1.\n",
    "\n",
    "        Returns:\n",
    "            SimpleGradientBoosting: self.\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).astype(float)\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        self.trees_ = []\n",
    "\n",
    "        if self.task == \"regression\":\n",
    "            # F0 = среднее по y\n",
    "            self.init_ = float(np.mean(y))\n",
    "            F = np.full(n_samples, self.init_, dtype=float)\n",
    "\n",
    "            for m in range(self.n_estimators):\n",
    "                residuals = y - F\n",
    "\n",
    "                idx = self._subsample_indices(n_samples)\n",
    "\n",
    "                base = MyDecisionTree(task=\"regression\",\n",
    "                                      max_depth=self.max_depth,\n",
    "                                      min_samples_split=self.min_samples_split)\n",
    "                base.fit(X[idx], residuals[idx])\n",
    "                self.trees_.append(base)\n",
    "\n",
    "                F += self.learning_rate * base.predict(X)\n",
    "\n",
    "        else:\n",
    "            unique = np.unique(y)\n",
    "            if set(unique.tolist()) - {0.0, 1.0}:\n",
    "                raise ValueError(\"Для task='binary' ожидаются метки 0/1.\")\n",
    "\n",
    "            prior = float(np.mean(y))\n",
    "            self.init_ = _logit(prior)\n",
    "            F = np.full(n_samples, self.init_, dtype=float)\n",
    "\n",
    "            for m in range(self.n_estimators):\n",
    "                p = _sigmoid(F)\n",
    "                residuals = y - p\n",
    "\n",
    "                idx = self._subsample_indices(n_samples)\n",
    "\n",
    "                base = MyDecisionTree(task=\"regression\",\n",
    "                                      max_depth=self.max_depth,\n",
    "                                      min_samples_split=self.min_samples_split)\n",
    "                base.fit(X[idx], residuals[idx])\n",
    "                self.trees_.append(base)\n",
    "\n",
    "                F += self.learning_rate * base.predict(X)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Делает предсказания.\n",
    "\n",
    "        Для 'regression' возвращает вещественные числа.\n",
    "        Для 'binary' возвращает метки классов 0/1 по порогу 0.5.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Матрица признаков (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Вектор предсказаний формы (n_samples,).\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        if self.task == \"regression\":\n",
    "            return self._predict_regression(X)\n",
    "        else:\n",
    "            proba = self.predict_proba(X)\n",
    "            return (proba >= 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Возвращает вероятность класса 1 (только для 'binary').\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Матрица признаков (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Вектор вероятностей формы (n_samples,).\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Если task != 'binary'.\n",
    "        \"\"\"\n",
    "        if self.task != \"binary\":\n",
    "            raise ValueError(\"predict_proba доступен только для task='binary'.\")\n",
    "        X = np.array(X)\n",
    "        F = self._predict_logit(X)\n",
    "        return _sigmoid(F)\n",
    "\n",
    "    def _subsample_indices(self, n_samples):\n",
    "        \"\"\"Возвращает индексы подвыборки для стохастического бустинга.\n",
    "\n",
    "        Args:\n",
    "            n_samples (int): Общее число объектов.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Индексы выбранных объектов.\n",
    "        \"\"\"\n",
    "        if self.subsample >= 1.0:\n",
    "            return np.arange(n_samples)\n",
    "        k = max(1, int(self.subsample * n_samples))\n",
    "        return self.rs_.choice(n_samples, size=k, replace=False)\n",
    "\n",
    "    def _predict_regression(self, X):\n",
    "        \"\"\"Собирает сумму предсказаний деревьев (регрессия).\"\"\"\n",
    "        y_hat = np.full(X.shape[0], self.init_, dtype=float)\n",
    "        for t in self.trees_:\n",
    "            y_hat += self.learning_rate * t.predict(X)\n",
    "        return y_hat\n",
    "\n",
    "    def _predict_logit(self, X):\n",
    "        \"\"\"Собирает логиты для 'binary' (до применения сигмоиды).\"\"\"\n",
    "        F = np.full(X.shape[0], self.init_, dtype=float)\n",
    "        for t in self.trees_:\n",
    "            F += self.learning_rate * t.predict(X)\n",
    "        return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca23d9c-56ef-42e6-be43-6ec3c2e6f03d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
