{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a9eba4-fb93-4a84-ae94-7fc16595a1ab",
   "metadata": {},
   "source": [
    "## 1. Word2Vec\n",
    "\n",
    "### Что это\n",
    "**Алгоритм обучения векторных представлений слов (embeddings)**.  \n",
    "Слова с похожим смыслом → близкие векторы.\n",
    "\n",
    "### Основные идеи\n",
    "- **CBOW** — контекст → слово\n",
    "- **Skip-gram** — слово → контекст\n",
    "\n",
    "### Где используется\n",
    "- поиск похожих слов\n",
    "- семантические признаки для ML\n",
    "- кластеризация слов\n",
    "\n",
    "### Важно\n",
    "- реализуется через `gensim`\n",
    "\n",
    "### Минимальный пример (gensim)\n",
    "```python\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "texts = [\n",
    "    \"I love natural language processing\",\n",
    "    \"Word2Vec creates word embeddings\"\n",
    "]\n",
    "\n",
    "sentences = [simple_preprocess(t) for t in texts]\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=50,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    sg=1  # Skip-gram\n",
    ")\n",
    "\n",
    "Похожие слова:\n",
    "model.wv.most_similar(\"love\")\n",
    "\n",
    "Получение вектора слова:\n",
    "vector = model.wv[\"love\"]\n",
    "\n",
    "Косинусная близость:\n",
    "model.wv.similarity(\"love\", \"learning\")\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3968a-e90a-4530-8b58-d418d80ff4ea",
   "metadata": {},
   "source": [
    "# NLTK — опорный конспект\n",
    "\n",
    "## Что это\n",
    "**NLTK (Natural Language Toolkit)** — классическая библиотека для обработки естественного языка, часто используется в обучении и исследованиях.\n",
    "\n",
    "## Основной функционал\n",
    "- токенизация текста\n",
    "- стемминг\n",
    "- лемматизация\n",
    "- POS-tagging\n",
    "- доступ к корпусам текстов\n",
    "\n",
    "## Когда использовать\n",
    "- изучение NLP\n",
    "- эксперименты\n",
    "- базовая предобработка текста\n",
    "\n",
    "## Установка\n",
    "```bash\n",
    "pip install nltk\n",
    "```\n",
    "## Токенизация\n",
    "```python\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "text = \"Natural Language Processing is interesting\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n",
    "```\n",
    "\n",
    "## Лемматизация\n",
    "```python\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "print(lemmas)\n",
    "```\n",
    "\n",
    "## Стемминг\n",
    "```python\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stems = [stemmer.stem(w) for w in tokens]\n",
    "print(stems)\n",
    "```\n",
    "\n",
    "## Плюсы: \n",
    "- много алгоритмов\n",
    "- хорошо подходит для обучения\n",
    "\n",
    "## Минусы:\n",
    "- медленнее современных библиотек\n",
    "- не подходит для production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d406c-7799-4b7f-aa9b-cff6b10cd312",
   "metadata": {},
   "source": [
    "# Gensim.\n",
    "\n",
    "## Что это\n",
    "**gensim** — библиотека для семантического моделирования текста и векторных представлений.\n",
    "\n",
    "## Основной функционал\n",
    "- Word2Vec\n",
    "- FastText\n",
    "- Doc2Vec\n",
    "- LDA (topic modeling)\n",
    "- поиск семантической близости\n",
    "\n",
    "## Когда использовать\n",
    "- обучение эмбеддингов\n",
    "- тематическое моделирование\n",
    "- работа с большими корпусами текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259192b-ea62-464d-ac04-1751539a1dfc",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "\n",
    "## Что это\n",
    "**spaCy** — быстрая и современная библиотека для обработки естественного языка, ориентированная на **production** и практические задачи NLP.\n",
    "\n",
    "\n",
    "\n",
    "## Зачем нужен\n",
    "- быстрая предобработка текста\n",
    "- лемматизация и POS-tagging\n",
    "- распознавание именованных сущностей (NER)\n",
    "- подготовка данных для ML / DL моделей\n",
    "\n",
    "\n",
    "\n",
    "## Основной функционал\n",
    "- токенизация\n",
    "- лемматизация\n",
    "- POS-tagging (части речи)\n",
    "- NER (Named Entity Recognition)\n",
    "- dependency parsing\n",
    "- пайплайны обработки текста\n",
    "\n",
    "\n",
    "\n",
    "## Когда использовать\n",
    "- реальные проекты\n",
    "- подготовка текстов для ML\n",
    "- когда важна скорость и стабильность\n",
    "\n",
    "\n",
    "## Код\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "## Токенизация и лемматизация\n",
    "\n",
    "doc = nlp(\"Cats are running faster than dogs\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_)\n",
    "\n",
    "\n",
    "## POS-tagging\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)\n",
    "\n",
    "## Named Entity Recognition (NER)\n",
    "\n",
    "doc = nlp(\"Apple is looking at buying a startup in London\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "## Очистка и нормализация текста\n",
    "\n",
    "def normalize(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return \" \".join(\n",
    "        token.lemma_\n",
    "        for token in doc\n",
    "        if token.is_alpha and not token.is_stop\n",
    "    )\n",
    "\n",
    "print(normalize(\"Cats are running faster than the dogs!\"))\n",
    "\n",
    "```\n",
    "\n",
    "## Плюсы: \n",
    "- очень высокая скорость\n",
    "- удобен для production\n",
    "- хорошие предобученные модели\n",
    "\n",
    "## Минусы:\n",
    "- не обучает Word2Vec (использует готовые эмбеддинги)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0790f89-8f41-4506-915f-58f4924dae8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
