{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNKgqyYtklpi",
    "outputId": "cf2d01e8-7655-4b29-d677-9c15bbbb5fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'gtzan-dataset-music-genre-classification' dataset.\n",
      "Path to dataset files: /kaggle/input/gtzan-dataset-music-genre-classification\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"andradaolteanu/gtzan-dataset-music-genre-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GSzwUYo7l6zN"
   },
   "outputs": [],
   "source": [
    "import os, random, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YNHRVYByyF94"
   },
   "outputs": [],
   "source": [
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "tOusRFdwmeEb",
    "outputId": "f79f5a6f-5b0c-4cb1-f7be-6e76776de259"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "sounds_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-8342cf98-1a78-43c2-9fce-1ec1cdaaa151\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.0.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335406</td>\n",
       "      <td>0.091048</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1773.065032</td>\n",
       "      <td>167541.630869</td>\n",
       "      <td>1972.744388</td>\n",
       "      <td>117335.771563</td>\n",
       "      <td>...</td>\n",
       "      <td>39.687145</td>\n",
       "      <td>-3.241280</td>\n",
       "      <td>36.488243</td>\n",
       "      <td>0.722209</td>\n",
       "      <td>38.099152</td>\n",
       "      <td>-5.050335</td>\n",
       "      <td>33.618073</td>\n",
       "      <td>-0.243027</td>\n",
       "      <td>43.771767</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00000.1.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.343065</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>1816.693777</td>\n",
       "      <td>90525.690866</td>\n",
       "      <td>2010.051501</td>\n",
       "      <td>65671.875673</td>\n",
       "      <td>...</td>\n",
       "      <td>64.748276</td>\n",
       "      <td>-6.055294</td>\n",
       "      <td>40.677654</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>51.264091</td>\n",
       "      <td>-2.837699</td>\n",
       "      <td>97.030830</td>\n",
       "      <td>5.784063</td>\n",
       "      <td>59.943081</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00000.2.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>1788.539719</td>\n",
       "      <td>111407.437613</td>\n",
       "      <td>2084.565132</td>\n",
       "      <td>75124.921716</td>\n",
       "      <td>...</td>\n",
       "      <td>67.336563</td>\n",
       "      <td>-1.768610</td>\n",
       "      <td>28.348579</td>\n",
       "      <td>2.378768</td>\n",
       "      <td>45.717648</td>\n",
       "      <td>-1.938424</td>\n",
       "      <td>53.050835</td>\n",
       "      <td>2.517375</td>\n",
       "      <td>33.105122</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00000.3.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>1655.289045</td>\n",
       "      <td>111952.284517</td>\n",
       "      <td>1960.039988</td>\n",
       "      <td>82913.639269</td>\n",
       "      <td>...</td>\n",
       "      <td>47.739452</td>\n",
       "      <td>-3.841155</td>\n",
       "      <td>28.337118</td>\n",
       "      <td>1.218588</td>\n",
       "      <td>34.770935</td>\n",
       "      <td>-3.580352</td>\n",
       "      <td>50.836224</td>\n",
       "      <td>3.630866</td>\n",
       "      <td>32.023678</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00000.4.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>1630.656199</td>\n",
       "      <td>79667.267654</td>\n",
       "      <td>1948.503884</td>\n",
       "      <td>60204.020268</td>\n",
       "      <td>...</td>\n",
       "      <td>30.336359</td>\n",
       "      <td>0.664582</td>\n",
       "      <td>45.880913</td>\n",
       "      <td>1.689446</td>\n",
       "      <td>51.363583</td>\n",
       "      <td>-3.392489</td>\n",
       "      <td>26.738789</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>29.146694</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>rock.00099.5.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.349126</td>\n",
       "      <td>0.080515</td>\n",
       "      <td>0.050019</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1499.083005</td>\n",
       "      <td>164266.886443</td>\n",
       "      <td>1718.707215</td>\n",
       "      <td>85931.574523</td>\n",
       "      <td>...</td>\n",
       "      <td>42.485981</td>\n",
       "      <td>-9.094270</td>\n",
       "      <td>38.326839</td>\n",
       "      <td>-4.246976</td>\n",
       "      <td>31.049839</td>\n",
       "      <td>-5.625813</td>\n",
       "      <td>48.804092</td>\n",
       "      <td>1.818823</td>\n",
       "      <td>38.966969</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>rock.00099.6.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.372564</td>\n",
       "      <td>0.082626</td>\n",
       "      <td>0.057897</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1847.965128</td>\n",
       "      <td>281054.935973</td>\n",
       "      <td>1906.468492</td>\n",
       "      <td>99727.037054</td>\n",
       "      <td>...</td>\n",
       "      <td>32.415203</td>\n",
       "      <td>-12.375726</td>\n",
       "      <td>66.418587</td>\n",
       "      <td>-3.081278</td>\n",
       "      <td>54.414265</td>\n",
       "      <td>-11.960546</td>\n",
       "      <td>63.452255</td>\n",
       "      <td>0.428857</td>\n",
       "      <td>18.697033</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>rock.00099.7.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.347481</td>\n",
       "      <td>0.089019</td>\n",
       "      <td>0.052403</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>1346.157659</td>\n",
       "      <td>662956.246325</td>\n",
       "      <td>1561.859087</td>\n",
       "      <td>138762.841945</td>\n",
       "      <td>...</td>\n",
       "      <td>78.228149</td>\n",
       "      <td>-2.524483</td>\n",
       "      <td>21.778994</td>\n",
       "      <td>4.809936</td>\n",
       "      <td>25.980829</td>\n",
       "      <td>1.775686</td>\n",
       "      <td>48.582378</td>\n",
       "      <td>-0.299545</td>\n",
       "      <td>41.586990</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>rock.00099.8.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.387527</td>\n",
       "      <td>0.084815</td>\n",
       "      <td>0.066430</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>2084.515327</td>\n",
       "      <td>203891.039161</td>\n",
       "      <td>2018.366254</td>\n",
       "      <td>22860.992562</td>\n",
       "      <td>...</td>\n",
       "      <td>28.323744</td>\n",
       "      <td>-5.363541</td>\n",
       "      <td>17.209942</td>\n",
       "      <td>6.462601</td>\n",
       "      <td>21.442928</td>\n",
       "      <td>2.354765</td>\n",
       "      <td>24.843613</td>\n",
       "      <td>0.675824</td>\n",
       "      <td>12.787750</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>rock.00099.9.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.369293</td>\n",
       "      <td>0.086759</td>\n",
       "      <td>0.050524</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1634.330126</td>\n",
       "      <td>411429.169769</td>\n",
       "      <td>1867.422378</td>\n",
       "      <td>119722.211518</td>\n",
       "      <td>...</td>\n",
       "      <td>38.801735</td>\n",
       "      <td>-11.598399</td>\n",
       "      <td>58.983097</td>\n",
       "      <td>-0.178517</td>\n",
       "      <td>55.761299</td>\n",
       "      <td>-6.903252</td>\n",
       "      <td>39.485901</td>\n",
       "      <td>-3.412534</td>\n",
       "      <td>31.727489</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9990 rows × 60 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8342cf98-1a78-43c2-9fce-1ec1cdaaa151')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8342cf98-1a78-43c2-9fce-1ec1cdaaa151 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8342cf98-1a78-43c2-9fce-1ec1cdaaa151');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "               filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0     blues.00000.0.wav   66149          0.335406         0.091048  0.130405   \n",
       "1     blues.00000.1.wav   66149          0.343065         0.086147  0.112699   \n",
       "2     blues.00000.2.wav   66149          0.346815         0.092243  0.132003   \n",
       "3     blues.00000.3.wav   66149          0.363639         0.086856  0.132565   \n",
       "4     blues.00000.4.wav   66149          0.335579         0.088129  0.143289   \n",
       "...                 ...     ...               ...              ...       ...   \n",
       "9985   rock.00099.5.wav   66149          0.349126         0.080515  0.050019   \n",
       "9986   rock.00099.6.wav   66149          0.372564         0.082626  0.057897   \n",
       "9987   rock.00099.7.wav   66149          0.347481         0.089019  0.052403   \n",
       "9988   rock.00099.8.wav   66149          0.387527         0.084815  0.066430   \n",
       "9989   rock.00099.9.wav   66149          0.369293         0.086759  0.050524   \n",
       "\n",
       "       rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0     0.003521             1773.065032          167541.630869   \n",
       "1     0.001450             1816.693777           90525.690866   \n",
       "2     0.004620             1788.539719          111407.437613   \n",
       "3     0.002448             1655.289045          111952.284517   \n",
       "4     0.001701             1630.656199           79667.267654   \n",
       "...        ...                     ...                    ...   \n",
       "9985  0.000097             1499.083005          164266.886443   \n",
       "9986  0.000088             1847.965128          281054.935973   \n",
       "9987  0.000701             1346.157659          662956.246325   \n",
       "9988  0.000320             2084.515327          203891.039161   \n",
       "9989  0.000067             1634.330126          411429.169769   \n",
       "\n",
       "      spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0                 1972.744388           117335.771563  ...   39.687145   \n",
       "1                 2010.051501            65671.875673  ...   64.748276   \n",
       "2                 2084.565132            75124.921716  ...   67.336563   \n",
       "3                 1960.039988            82913.639269  ...   47.739452   \n",
       "4                 1948.503884            60204.020268  ...   30.336359   \n",
       "...                       ...                     ...  ...         ...   \n",
       "9985              1718.707215            85931.574523  ...   42.485981   \n",
       "9986              1906.468492            99727.037054  ...   32.415203   \n",
       "9987              1561.859087           138762.841945  ...   78.228149   \n",
       "9988              2018.366254            22860.992562  ...   28.323744   \n",
       "9989              1867.422378           119722.211518  ...   38.801735   \n",
       "\n",
       "      mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  \\\n",
       "0       -3.241280   36.488243     0.722209   38.099152    -5.050335   \n",
       "1       -6.055294   40.677654     0.159015   51.264091    -2.837699   \n",
       "2       -1.768610   28.348579     2.378768   45.717648    -1.938424   \n",
       "3       -3.841155   28.337118     1.218588   34.770935    -3.580352   \n",
       "4        0.664582   45.880913     1.689446   51.363583    -3.392489   \n",
       "...           ...         ...          ...         ...          ...   \n",
       "9985    -9.094270   38.326839    -4.246976   31.049839    -5.625813   \n",
       "9986   -12.375726   66.418587    -3.081278   54.414265   -11.960546   \n",
       "9987    -2.524483   21.778994     4.809936   25.980829     1.775686   \n",
       "9988    -5.363541   17.209942     6.462601   21.442928     2.354765   \n",
       "9989   -11.598399   58.983097    -0.178517   55.761299    -6.903252   \n",
       "\n",
       "      mfcc19_var  mfcc20_mean  mfcc20_var  label  \n",
       "0      33.618073    -0.243027   43.771767  blues  \n",
       "1      97.030830     5.784063   59.943081  blues  \n",
       "2      53.050835     2.517375   33.105122  blues  \n",
       "3      50.836224     3.630866   32.023678  blues  \n",
       "4      26.738789     0.536961   29.146694  blues  \n",
       "...          ...          ...         ...    ...  \n",
       "9985   48.804092     1.818823   38.966969   rock  \n",
       "9986   63.452255     0.428857   18.697033   rock  \n",
       "9987   48.582378    -0.299545   41.586990   rock  \n",
       "9988   24.843613     0.675824   12.787750   rock  \n",
       "9989   39.485901    -3.412534   31.727489   rock  \n",
       "\n",
       "[9990 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sounds_df = pd.read_csv('/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_3_sec.csv')\n",
    "sounds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dd74qeV9pL5N"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "SR = 22050\n",
    "\n",
    "N_MELS = 128\n",
    "N_FFT = 2048\n",
    "HOP = 512\n",
    "\n",
    "SEG_SEC = 3.0\n",
    "SEG_SAMPLES = int(SR * SEG_SEC)\n",
    "\n",
    "ROOT_OF_GENRES = \"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zLoOv5tsqZmi"
   },
   "outputs": [],
   "source": [
    "# Индексация датасета (аудиофайлы + метки)\n",
    "def list_gztan_files(root_dir):\n",
    "    items = [] # (path, label_id, label_name),\n",
    "    bad = []\n",
    "    genres = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "    g2i = {g:i for i,g in enumerate(genres)}\n",
    "\n",
    "    for g in genres:\n",
    "        folder = os.path.join(root_dir, g)\n",
    "        for fn in sorted(os.listdir(folder)):\n",
    "            if not fn.lower().endswith(\".wav\"):\n",
    "                continue\n",
    "\n",
    "            path = os.path.join(folder, fn)\n",
    "\n",
    "            try:\n",
    "                sf.info(path)\n",
    "                items.append((path, g2i[g], g))\n",
    "            except Exception:\n",
    "                bad.append(path)\n",
    "\n",
    "    if bad:\n",
    "        print(f\"[WARN] skipped bad audio files: {len(bad)}\")\n",
    "        print(\"\\n\".join(bad[:10]))\n",
    "\n",
    "    return items, g2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-E8HOXGVqtHy"
   },
   "outputs": [],
   "source": [
    "#Split по трекам\n",
    "def split_by_track(items, test_size=0.2):\n",
    "    paths = [p for p, y, g in items]\n",
    "    labels = [y for p, y, g in items]\n",
    "\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        np.arange(len(items)),\n",
    "        test_size=test_size,\n",
    "        random_state=SEED,\n",
    "        stratify=labels\n",
    "    )\n",
    "    train_items = [items[i] for i in train_idx]\n",
    "    val_items = [items[i] for i in val_idx]\n",
    "    return train_items, val_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "P4LkBvjTti2T"
   },
   "outputs": [],
   "source": [
    "class GTZANDataset(Dataset):\n",
    "    def __init__(self, items, augment=False):\n",
    "        self.items = items\n",
    "        self.augment = augment\n",
    "\n",
    "        # (path, label, offset_sample)\n",
    "        self.segments = []\n",
    "        for path, y, g in items:\n",
    "            # 30 сек превращаем в 10 сегментов по 3 секунды\n",
    "            num_seg = 10\n",
    "            for k in range(num_seg):\n",
    "                offset = k * SEG_SAMPLES\n",
    "                self.segments.append((path, y, offset))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "\n",
    "    def _load_segment(self, path, offset):\n",
    "        wav, _ = librosa.load(path, sr=SR, mono=True)\n",
    "        if len(wav) < SEG_SAMPLES:\n",
    "          wav = np.pad(wav, (0, SEG_SAMPLES - len(wav)))\n",
    "\n",
    "        wav = wav[offset:offset + SEG_SAMPLES]\n",
    "        # Мы решили, что бесполезно, т.к. уже выше удостоверились в 3 секундах\n",
    "        # if len(wav) < SEG_SAMPLES:\n",
    "        #     wav = np.pad(wav, (0, SEG_SAMPLES - len(wav)))\n",
    "        return wav\n",
    "\n",
    "    def _wav_to_mel(self, wav):\n",
    "        mel = librosa.feature.melspectrogram(\n",
    "            y=wav, sr=SR, n_fft=N_FFT, hop_length=HOP, n_mels=N_MELS, power=2.0\n",
    "        )\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        # нормализация\n",
    "        mel_db = (mel_db - mel_db.mean()) / (mel_db.std() + 1e-6)\n",
    "\n",
    "        # SpecAugment на спектрограмме (работает быстрее и стабильнее, чем «умные» аугментации на волне)\n",
    "        # Делаем только на train (augment=True)\n",
    "        if self.augment:\n",
    "            mel_db = self._spec_augment(mel_db)\n",
    "\n",
    "        return mel_db.astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, y, offset = self.segments[idx]\n",
    "        wav = self._load_segment(path, offset)\n",
    "\n",
    "        # аугментация\n",
    "        if self.augment:\n",
    "            if random.random() < 0.3:\n",
    "                wav = wav + 0.005 * np.random.randn(len(wav))\n",
    "            if random.random() < 0.3:\n",
    "                rate = random.uniform(0.9, 1.1)\n",
    "                wav = librosa.effects.time_stretch(wav, rate=rate)\n",
    "                wav = librosa.util.fix_length(wav, size=SEG_SAMPLES)\n",
    "\n",
    "        mel = self._wav_to_mel(wav)\n",
    "        x = torch.from_numpy(mel).unsqueeze(0)  # [1, n_mels, time]\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 11,
   "metadata": {
    "id": "Qq_JtQT9sPmh"
   },
   "outputs": [],
   "source": [
    "### Модели\n",
    "Ниже: **только CNN**, **CNN+RNN**, **CNN+RNN+Attention**. (Код моделей — в следующей ячейке.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJ7pxP8W-3ha"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "O7FJwXLPr-yJ"
   },
   "outputs": [],
   "source": [
    "class CNNBackbone(nn.Module):\n",
    "    \"\"\"Общий CNN-блок для всех подходов.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # [B, C, F', T']\n",
    "\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    \"\"\"Только CNN: глобальный pooling по (F, T) -> классификатор.\"\"\"\n",
    "    def __init__(self, n_classes=10, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.cnn = CNNBackbone()\n",
    "\n",
    "        # Глобальный mean+max pooling даёт обычно лучше, чем только mean\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(256 * 2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.cnn(x)  # [B, 256, F', T']\n",
    "        mean = z.mean(dim=(2,3))          # [B, 256]\n",
    "        mx = z.amax(dim=(2,3))            # [B, 256]\n",
    "        feats = torch.cat([mean, mx], dim=1)  # [B, 512]\n",
    "        return self.fc(self.dropout(feats)), None\n",
    "\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, h): # h: [B, T, H]\n",
    "        scores = self.proj(h).squeeze(-1) # [B, T]\n",
    "        alpha = torch.softmax(scores, dim=1) # [B, T]\n",
    "        context = (h * alpha.unsqueeze(-1)).sum(dim=1) # [B, H]\n",
    "        return context, alpha\n",
    "\n",
    "\n",
    "class CNNRNNClassifier(nn.Module):\n",
    "    \"\"\"CNN -> последовательность по времени -> BiGRU -> (pool/attention) -> классификатор.\"\"\"\n",
    "    def __init__(self, n_classes=10, use_attention=False, rnn_hidden=160, rnn_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "        self.cnn = CNNBackbone()\n",
    "\n",
    "        # вычисляем размер фич для RNN автоматически\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, N_MELS, math.ceil(SEG_SAMPLES / HOP) + 1)\n",
    "            z = self.cnn(dummy)\n",
    "            _, C, Fp, Tp = z.shape\n",
    "            rnn_in = C * Fp\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=rnn_in,\n",
    "            hidden_size=rnn_hidden,\n",
    "            num_layers=rnn_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.2 if rnn_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        rnn_out = 2 * rnn_hidden\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        if use_attention:\n",
    "            self.attn = TemporalAttention(rnn_out)\n",
    "            self.fc = nn.Linear(rnn_out, n_classes)\n",
    "        else:\n",
    "            # mean+max pooling по времени обычно лучше, чем брать last timestep\n",
    "            self.fc = nn.Linear(rnn_out * 2, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.cnn(x) # [B, C, F', T']\n",
    "        B, C, Fp, Tp = z.shape\n",
    "        z = z.permute(0, 3, 1, 2).contiguous().view(B, Tp, C*Fp) # [B, T', C*F']\n",
    "        h, _ = self.rnn(z) # [B, T', 2H]\n",
    "\n",
    "        if self.use_attention:\n",
    "            ctx, alpha = self.attn(h)\n",
    "            return self.fc(self.dropout(ctx)), alpha\n",
    "        else:\n",
    "            h_mean = h.mean(dim=1)  # [B, 2H]\n",
    "            h_max = h.amax(dim=1)   # [B, 2H]\n",
    "            feats = torch.cat([h_mean, h_max], dim=1)  # [B, 4H]\n",
    "            return self.fc(self.dropout(feats)), None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eULflQrtsbT0"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, max_grad_norm=1.0):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x, y in tqdm(loader, leave=False):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        logits, _ = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # стабилизация обучения (особенно для RNN)\n",
    "        if max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return total_loss/total, total_correct/total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for x, y in tqdm(loader, leave=False):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits, _ = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(y.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return total_loss/total, total_correct/total, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cQ81qtgjsl7B"
   },
   "outputs": [],
   "source": [
    "def run_experiment(train_items, val_items, model_kind=\"cnn\", epochs=18, batch_size=64, lr=3e-4, weight_decay=1e-4):\n",
    "    \"\"\"\n",
    "    model_kind:\n",
    "      - \"cnn\"             : только CNN\n",
    "      - \"cnn_rnn\"         : CNN + RNN (без attention)\n",
    "      - \"cnn_rnn_attn\"    : CNN + RNN + attention\n",
    "    \"\"\"\n",
    "    train_ds = GTZANDataset(train_items, augment=True)\n",
    "    val_ds = GTZANDataset(val_items, augment=False)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    if model_kind == \"cnn\":\n",
    "        model = CNNClassifier(n_classes=10).to(DEVICE)\n",
    "    elif model_kind == \"cnn_rnn\":\n",
    "        model = CNNRNNClassifier(n_classes=10, use_attention=False).to(DEVICE)\n",
    "    elif model_kind == \"cnn_rnn_attn\":\n",
    "        model = CNNRNNClassifier(n_classes=10, use_attention=True).to(DEVICE)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_kind: {model_kind}\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "\n",
    "    # Плавное снижение LR почти всегда даёт + к точности на GTZAN\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_dl, optimizer, criterion, max_grad_norm=1.0)\n",
    "        va_loss, va_acc, _, _ = eval_model(model, val_dl, criterion)\n",
    "        scheduler.step()\n",
    "\n",
    "        if va_acc > best_val_acc:\n",
    "            best_val_acc = va_acc\n",
    "            best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "\n",
    "        print(f\"epoch {ep:02d} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | val loss {va_loss:.4f} acc {va_acc:.4f} | lr {scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    va_loss, va_acc, preds, labels = eval_model(model, val_dl, criterion)\n",
    "    print(\"\\nVAL ACC:\", va_acc)\n",
    "    print(classification_report(labels, preds, digits=4))\n",
    "    return model, va_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHvYNCLuspDB",
    "outputId": "078bfc4d-f492-48b5-f3d9-693e6013e39d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] skipped bad audio files: 1\n",
      "/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/jazz/jazz.00054.wav\n",
      "tracks: 999 train: 799 val: 200\n",
      "genres: ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss 1.7015 acc 0.3892 | val loss 1.3922 acc 0.5215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 02 | train loss 1.2751 acc 0.5411 | val loss 1.1960 acc 0.5795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 03 | train loss 1.0904 acc 0.6223 | val loss 1.1056 acc 0.6235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 04 | train loss 0.9673 acc 0.6712 | val loss 1.0372 acc 0.6420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 05 | train loss 0.8501 acc 0.7140 | val loss 0.9031 acc 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 06 | train loss 0.7428 acc 0.7489 | val loss 0.8736 acc 0.6980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 07 | train loss 0.6525 acc 0.7809 | val loss 0.8314 acc 0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 08 | train loss 0.5980 acc 0.8043 | val loss 0.9571 acc 0.6680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 09 | train loss 0.5227 acc 0.8260 | val loss 0.7910 acc 0.7485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 | train loss 0.4602 acc 0.8484 | val loss 0.7773 acc 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 | train loss 0.4209 acc 0.8637 | val loss 0.7727 acc 0.7550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 | train loss 0.3762 acc 0.8776 | val loss 0.8033 acc 0.7470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VAL ACC: 0.755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7304    0.8400    0.7814       200\n",
      "           1     0.8981    0.9700    0.9327       200\n",
      "           2     0.7135    0.6350    0.6720       200\n",
      "           3     0.6422    0.7000    0.6699       200\n",
      "           4     0.7745    0.7900    0.7822       200\n",
      "           5     0.9176    0.8350    0.8743       200\n",
      "           6     0.9202    0.8650    0.8918       200\n",
      "           7     0.6250    0.8500    0.7203       200\n",
      "           8     0.6597    0.7850    0.7169       200\n",
      "           9     0.7568    0.2800    0.4088       200\n",
      "\n",
      "    accuracy                         0.7550      2000\n",
      "   macro avg     0.7638    0.7550    0.7450      2000\n",
      "weighted avg     0.7638    0.7550    0.7450      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss 1.3919 acc 0.5018 | val loss 1.0406 acc 0.6210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 02 | train loss 0.9258 acc 0.6822 | val loss 0.8216 acc 0.7245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 03 | train loss 0.7336 acc 0.7483 | val loss 0.8284 acc 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 04 | train loss 0.5974 acc 0.8039 | val loss 0.8828 acc 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 05 | train loss 0.5089 acc 0.8309 | val loss 0.7332 acc 0.7835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 06 | train loss 0.4469 acc 0.8511 | val loss 0.7785 acc 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 07 | train loss 0.3822 acc 0.8768 | val loss 0.7226 acc 0.7740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 08 | train loss 0.3332 acc 0.8887 | val loss 0.8062 acc 0.7650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 09 | train loss 0.3122 acc 0.8979 | val loss 1.0630 acc 0.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 | train loss 0.2675 acc 0.9101 | val loss 0.8274 acc 0.7655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 | train loss 0.2479 acc 0.9175 | val loss 0.8670 acc 0.7690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 | train loss 0.2002 acc 0.9339 | val loss 0.7900 acc 0.7940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VAL ACC: 0.794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9040    0.8950    0.8995       200\n",
      "           1     0.9037    0.9850    0.9426       200\n",
      "           2     0.6295    0.8750    0.7322       200\n",
      "           3     0.9036    0.3750    0.5300       200\n",
      "           4     0.7739    0.8900    0.8279       200\n",
      "           5     0.8428    0.9650    0.8998       200\n",
      "           6     0.9827    0.8500    0.9115       200\n",
      "           7     0.7048    0.8000    0.7494       200\n",
      "           8     0.7574    0.7650    0.7612       200\n",
      "           9     0.6667    0.5400    0.5967       200\n",
      "\n",
      "    accuracy                         0.7940      2000\n",
      "   macro avg     0.8069    0.7940    0.7851      2000\n",
      "weighted avg     0.8069    0.7940    0.7851      2000\n",
      "\n",
      "\n",
      "=== RESULT ===\n",
      "no attention: 0.755\n",
      "with attention: 0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "items, g2i = list_gztan_files(ROOT_OF_GENRES)\n",
    "train_items, val_items = split_by_track(items, test_size=0.2)\n",
    "\n",
    "print(\"tracks:\", len(items), \"train:\", len(train_items), \"val:\", len(val_items))\n",
    "print(\"genres:\", list(g2i.keys()))\n",
    "\n",
    "# 1) Только CNN\n",
    "model_cnn, acc_cnn = run_experiment(train_items, val_items, model_kind=\"cnn\", epochs=18)\n",
    "\n",
    "# 2) CNN + RNN\n",
    "model_cnn_rnn, acc_cnn_rnn = run_experiment(train_items, val_items, model_kind=\"cnn_rnn\", epochs=18)\n",
    "\n",
    "# 3) CNN + RNN + Attention\n",
    "model_attn, acc_attn = run_experiment(train_items, val_items, model_kind=\"cnn_rnn_attn\", epochs=18)\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(\"CNN only:            \", acc_cnn)\n",
    "print(\"CNN + RNN:           \", acc_cnn_rnn)\n",
    "print(\"CNN + RNN + Attention:\", acc_attn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba6939",
   "metadata": {},
   "source": [
    "## Когда лучше CNN / CNN+RNN / CNN+RNN+Attention (по смыслу звука)\n",
    "\n",
    "**Только CNN (по спектрограмме)** лучше всего, когда класс определяется в основном **локальными «рисунками»** на спектрограмме и порядок событий внутри окна не критичен:\n",
    "- короткие команды/слова (keyword spotting), отдельные звуки/удары, тип «тембра» инструмента;\n",
    "- жанр/сцена в аудио, где достаточно статистики текстур (гармоники, шум, «зерно» спектра);\n",
    "- когда нужен **максимальный speed** и простая модель (реал‑тайм, мобилка).\n",
    "\n",
    "**CNN + RNN** полезно, когда важна **последовательность** и длительные зависимости:\n",
    "- речь с более длинными фразами, фонемная/слоговая динамика, интонация;\n",
    "- события типа «A потом B» (например, шаги → дверь → тишина);\n",
    "- данные, где один и тот же «рисунок» может быть в разном порядке, и это меняет класс.\n",
    "\n",
    "**CNN + RNN + Attention** выигрывает, когда сигнал содержит **много «мусора»/тишины** и нужно *выделять* информативные моменты:\n",
    "- длинные записи, где полезное событие редкое и короткое (звонок, сирена, кашель);\n",
    "- ситуации с неоднородностью: начало/конец записи менее информативны, важны отдельные фрагменты;\n",
    "- когда в классе есть несколько под‑паттернов, и модель должна «переключаться» между ними.\n",
    "\n",
    "## Как ещё поднять accuracy (если всё равно не хватает)\n",
    "\n",
    "1) **Больше эпох + EarlyStopping** (GTZAN часто растёт до 25–35 эпох, но следи по val).\n",
    "2) Подстрой `batch_size` (часто 32 лучше по качеству, 64 быстрее).\n",
    "3) Усиль аугментации:\n",
    "   - добавь `pitch_shift` на волне (±1–2 полутона) и/или более сильный noise;\n",
    "   - увеличь masks в SpecAugment (но без фанатизма).\n",
    "4) Попробуй `n_mels=64` или `n_fft=1024` (иногда помогает под жанры/речь).\n",
    "5) Если есть GPU: включи `torch.backends.cudnn.benchmark=True` для ускорения.\n",
    "\n",
    "Если скажешь, **какая у тебя текущая val accuracy** после этих правок (по трём моделям), я подстрою гиперпараметры точечно под твой результат.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === CONFUSION MATRIX ===\n",
    "# Использует matplotlib (без seaborn)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Примеры вызова (раскомментируй нужное после получения предсказаний):\n",
    "# plot_confusion(test_labels_cnn, test_preds_cnn, 'CNN Confusion Matrix')\n",
    "# plot_confusion(test_labels_rnn, test_preds_rnn, 'CNN+RNN Confusion Matrix')\n",
    "# plot_confusion(test_labels_att, test_preds_att, 'CNN+RNN+Attention Confusion Matrix')\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}